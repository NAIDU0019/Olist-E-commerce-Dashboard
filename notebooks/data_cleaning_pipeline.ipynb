{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da8a807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Loading data...\n",
      "âœ… Products shape: (32951, 9)\n",
      "âœ… Orders shape: (112650, 7)\n",
      "âœ… Added English category translations\n",
      "âœ… Cleaned data saved to cleaned_data/cleaned_products.csv\n",
      "ðŸ“Š Visualization saved to visuals/price_distribution.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAJUA\\AppData\\Local\\Temp\\ipykernel_29840\\1407826757.py:128: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=top_cats.values, y=top_cats.index, palette='viridis')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbfaf6128e494150b255227b4aa90a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 42.94it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068094441cd6463788dbc7140c1f8fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0d50c4de8343e0b97b177bfafb54c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac9120ecc6746fd8a4629d0f5538d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ EDA report saved to visuals/olist_product_report.html\n",
      "\n",
      "ðŸ“Š Summary Statistics:\n",
      "Total products: 41316\n",
      "Unique categories: 73\n",
      "Median price: R$80.00\n",
      "Average price: R$130.28\n",
      "\n",
      "Price Bucket Distribution:\n",
      "price_bucket\n",
      "<20         3427\n",
      "20-50      10081\n",
      "50-100     11012\n",
      "100-200    10261\n",
      "200-500     5002\n",
      "500+        1533\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# ðŸ§¼ Enhanced E-commerce Data Cleaning Pipeline (Olist Dataset)\n",
    "# =========================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# === Paths ===\n",
    "RAW_PRODUCTS = \"raw_data/olist_products_dataset.csv\"\n",
    "RAW_ORDERS = \"raw_data/olist_order_items_dataset.csv\"\n",
    "TRANSLATIONS = \"raw_data/product_category_name_translation.csv\"\n",
    "CLEANED_PATH = \"cleaned_data/cleaned_products.csv\"\n",
    "VISUALS_PATH = \"visuals/price_distribution.png\"\n",
    "REPORT_PATH = \"visuals/olist_product_report.html\"\n",
    "\n",
    "# === Create folders if not exist ===\n",
    "os.makedirs(\"raw_data\", exist_ok=True)\n",
    "os.makedirs(\"cleaned_data\", exist_ok=True)\n",
    "os.makedirs(\"visuals\", exist_ok=True)\n",
    "\n",
    "# === Load Datasets ===\n",
    "print(\"ðŸ”¹ Loading data...\")\n",
    "products_df = pd.read_csv(RAW_PRODUCTS)\n",
    "orders_df = pd.read_csv(RAW_ORDERS)\n",
    "\n",
    "print(\"âœ… Products shape:\", products_df.shape)\n",
    "print(\"âœ… Orders shape:\", orders_df.shape)\n",
    "\n",
    "# === Merge product and price info ===\n",
    "merged_df = pd.merge(\n",
    "    products_df, \n",
    "    orders_df[['product_id', 'price']], \n",
    "    on='product_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# === Step 1: Drop Duplicates ===\n",
    "merged_df = merged_df.drop_duplicates()\n",
    "\n",
    "# === Step 2: Handle Missing Values ===\n",
    "# Fill missing prices with median of the product's category\n",
    "merged_df['price'] = merged_df.groupby('product_category_name')['price'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "# If still missing (entire category missing), fill with global median\n",
    "merged_df['price'] = merged_df['price'].fillna(merged_df['price'].median())\n",
    "\n",
    "# Drop rows with missing category names\n",
    "merged_df = merged_df.dropna(subset=['product_category_name'])\n",
    "\n",
    "# === Step 3: Normalize Strings ===\n",
    "merged_df['product_category_name'] = (\n",
    "    merged_df['product_category_name']\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(' ', '_')\n",
    ")\n",
    "\n",
    "# === Step 4: Add English Translations ===\n",
    "if os.path.exists(TRANSLATIONS):\n",
    "    translations = pd.read_csv(TRANSLATIONS)\n",
    "    merged_df = pd.merge(\n",
    "        merged_df, \n",
    "        translations, \n",
    "        how='left', \n",
    "        on='product_category_name'\n",
    "    )\n",
    "    print(\"âœ… Added English category translations\")\n",
    "\n",
    "# === Step 5: Feature Engineering ===\n",
    "# Price Buckets\n",
    "price_bins = [0, 20, 50, 100, 200, 500, float('inf')]\n",
    "price_labels = ['<20', '20-50', '50-100', '100-200', '200-500', '500+']\n",
    "\n",
    "merged_df['price_bucket'] = pd.cut(\n",
    "    merged_df['price'],\n",
    "    bins=price_bins,\n",
    "    labels=price_labels\n",
    ")\n",
    "\n",
    "# Category Popularity\n",
    "category_counts = merged_df['product_category_name'].value_counts()\n",
    "merged_df['category_popularity'] = (\n",
    "    merged_df['product_category_name']\n",
    "    .map(category_counts)\n",
    "    .astype('int')\n",
    ")\n",
    "\n",
    "# Product Dimensions (if available)\n",
    "dimension_cols = ['product_length_cm', 'product_height_cm', 'product_width_cm']\n",
    "if all(col in merged_df.columns for col in dimension_cols):\n",
    "    merged_df['product_volume_cm3'] = (\n",
    "        merged_df['product_length_cm'] * \n",
    "        merged_df['product_height_cm'] * \n",
    "        merged_df['product_width_cm']\n",
    "    )\n",
    "\n",
    "# === Step 6: Outlier Removal ===\n",
    "Q1 = merged_df['price'].quantile(0.05)  # Using 5th percentile for more conservative cutoff\n",
    "Q3 = merged_df['price'].quantile(0.95)\n",
    "IQR = Q3 - Q1\n",
    "merged_df = merged_df[~((merged_df['price'] < (Q1 - 1.5 * IQR)) | \n",
    "                      (merged_df['price'] > (Q3 + 1.5 * IQR)))]\n",
    "\n",
    "# === Step 7: Save Cleaned Data ===\n",
    "merged_df.to_csv(CLEANED_PATH, index=False)\n",
    "print(f\"âœ… Cleaned data saved to {CLEANED_PATH}\")\n",
    "\n",
    "# === Step 8: Generate Visualizations ===\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(merged_df['price'], bins=50, kde=True, color='skyblue')\n",
    "plt.title(\"Price Distribution After Cleaning\", fontsize=14)\n",
    "plt.xlabel(\"Price (R$)\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(VISUALS_PATH, dpi=300)\n",
    "plt.close()  # Close the plot to free memory\n",
    "print(f\"ðŸ“Š Visualization saved to {VISUALS_PATH}\")\n",
    "\n",
    "# Top Categories by Product Count\n",
    "if 'product_category_name_english' in merged_df.columns:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_cats = merged_df['product_category_name_english'].value_counts().head(10)\n",
    "    sns.barplot(x=top_cats.values, y=top_cats.index, palette='viridis')\n",
    "    plt.title(\"Top 10 Product Categories by Count\", fontsize=14)\n",
    "    plt.xlabel(\"Count\", fontsize=12)\n",
    "    plt.ylabel(\"Category\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visuals/top_categories.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# === Step 9: Generate EDA Report ===\n",
    "profile = ProfileReport(\n",
    "    merged_df, \n",
    "    title=\"Olist Product Report\", \n",
    "    explorative=True,\n",
    "    minimal=True\n",
    ")\n",
    "profile.to_file(REPORT_PATH)\n",
    "print(f\"ðŸ“„ EDA report saved to {REPORT_PATH}\")\n",
    "\n",
    "# === Step 10: Summary Statistics ===\n",
    "print(\"\\nðŸ“Š Summary Statistics:\")\n",
    "print(f\"Total products: {len(merged_df)}\")\n",
    "print(f\"Unique categories: {merged_df['product_category_name'].nunique()}\")\n",
    "print(f\"Median price: R${merged_df['price'].median():.2f}\")\n",
    "print(f\"Average price: R${merged_df['price'].mean():.2f}\")\n",
    "print(\"\\nPrice Bucket Distribution:\")\n",
    "print(merged_df['price_bucket'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dae705b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Popular Categories (by Product Count):\n",
      "product_category_name_english\n",
      "bed_bath_table           3748\n",
      "sports_leisure           3553\n",
      "health_beauty            3190\n",
      "furniture_decor          3067\n",
      "housewares               2909\n",
      "computers_accessories    2314\n",
      "auto                     2186\n",
      "watches_gifts            1993\n",
      "toys                     1836\n",
      "telephony                1516\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average Price per Category:\n",
      "product_category_name_english\n",
      "computers                                697.844138\n",
      "home_appliances_2                        338.812719\n",
      "agro_industry_and_commerce               279.522360\n",
      "watches_gifts                            265.853116\n",
      "small_appliances_home_oven_and_coffee    263.178000\n",
      "                                            ...    \n",
      "cds_dvds_musicals                         55.000000\n",
      "food_drink                                53.616899\n",
      "diapers_and_hygiene                       52.972667\n",
      "dvds_blu_ray                              52.419200\n",
      "flowers                                   34.783810\n",
      "Name: price, Length: 71, dtype: float64\n",
      "\n",
      "Price Variation Across Buckets:\n",
      "                    mean         std\n",
      "price_bucket                        \n",
      "<20            15.433496    4.080074\n",
      "20-50          36.229826    8.824221\n",
      "50-100         75.316466   14.912720\n",
      "100-200       146.079373   28.898350\n",
      "200-500       303.143942   78.655984\n",
      "500+          730.515734  171.203054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAJUA\\AppData\\Local\\Temp\\ipykernel_29840\\3312925934.py:12: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  price_bucket_variation = merged_df.groupby('price_bucket')['price'].agg(['mean', 'std'])\n"
     ]
    }
   ],
   "source": [
    "# Top 10 most popular categories (by product count)\n",
    "top_categories = merged_df['product_category_name_english'].value_counts().head(10)\n",
    "print(\"Top 10 Most Popular Categories (by Product Count):\")\n",
    "print(top_categories)\n",
    "\n",
    "# Average price per category\n",
    "avg_price_per_category = merged_df.groupby('product_category_name_english')['price'].mean().sort_values(ascending=False)\n",
    "print(\"\\nAverage Price per Category:\")\n",
    "print(avg_price_per_category)\n",
    "\n",
    "# Price variation across buckets\n",
    "price_bucket_variation = merged_df.groupby('price_bucket')['price'].agg(['mean', 'std'])\n",
    "print(\"\\nPrice Variation Across Buckets:\")\n",
    "print(price_bucket_variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# === Prepare Data ===\n",
    "# Select features and target\n",
    "features = ['product_name_lenght', 'product_description_lenght', 'product_photos_qty', \n",
    "            'product_weight_g', 'product_volume_cm3', 'category_popularity']\n",
    "target = 'price_bucket'\n",
    "\n",
    "# Drop rows with missing values in selected features or target\n",
    "ml_data = merged_df[features + [target]].dropna()\n",
    "\n",
    "# Encode target variable (price_bucket)\n",
    "label_encoder = LabelEncoder()\n",
    "ml_data[target] = label_encoder.fit_transform(ml_data[target])\n",
    "\n",
    "# Split data into train and test sets\n",
    "X = ml_data[features]\n",
    "y = ml_data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Train Model ===\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# === Evaluate Model ===\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90fa801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    # Load the cleaned data\n",
    "CLEANED_PATH = 'cleaned_data/cleaned_products.csv'\n",
    "merged_df = pd.read_csv(CLEANED_PATH)\n",
    "top_cats = merged_df['product_category_name_english'].value_counts().head(10)\n",
    "avg_price_per_category = merged_df.groupby('product_category_name_english')['price'].mean().sort_values(ascending=False)\n",
    "top_categories = merged_df['product_category_name_english'].value_counts().head(10)\n",
    "price_bucket_variation = merged_df.groupby('price_bucket')['price'].agg(['mean', 'std'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Prepare Data ===\n",
    "# Select features and target\n",
    "\n",
    "\n",
    "# === Streamlit App ===\n",
    "st.title(\"Olist E-commerce Dashboard\")\n",
    "\n",
    "# Sidebar\n",
    "st.sidebar.header(\"Navigation\")\n",
    "page = st.sidebar.selectbox(\"Select a Page\", [\"Overview\", \"Category Insights\", \"Price Analysis\", \"Model Performance\"])\n",
    "\n",
    "# Overview Page\n",
    "if page == \"Overview\":\n",
    "    st.header(\"Overview\")\n",
    "    st.write(\"### Cleaned Data Summary\")\n",
    "    st.write(merged_df.describe())\n",
    "    st.write(\"### Top 10 Categories by Product Count\")\n",
    "    st.bar_chart(top_cats)\n",
    "\n",
    "# Category Insights Page\n",
    "elif page == \"Category Insights\":\n",
    "    st.header(\"Category Insights\")\n",
    "    st.write(\"### Average Price per Category\")\n",
    "    st.bar_chart(avg_price_per_category)\n",
    "    st.write(\"### Top 10 Most Popular Categories\")\n",
    "    st.bar_chart(top_categories)\n",
    "\n",
    "# Price Analysis Page\n",
    "elif page == \"Price Analysis\":\n",
    "    st.header(\"Price Analysis\")\n",
    "    st.write(\"### Price Distribution\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.histplot(merged_df['price'], bins=50, kde=True, color='skyblue', ax=ax)\n",
    "    ax.set_title(\"Price Distribution After Cleaning\")\n",
    "    ax.set_xlabel(\"Price (R$)\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    st.pyplot(fig)\n",
    "\n",
    "    st.write(\"### Price Variation Across Buckets\")\n",
    "    st.write(price_bucket_variation)\n",
    "\n",
    "# Model Performance Page\n",
    "elif page == \"Model Performance\":\n",
    "    st.header(\"Model Performance\")\n",
    "    st.write(\"### Classification Report\")\n",
    "    st.text(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "    st.write(\"### Accuracy\")\n",
    "    st.metric(\"Accuracy\", f\"{accuracy_score(y_test, y_pred):.2%}\")\n",
    "\n",
    "    st.write(\"### Feature Importance\")\n",
    "    feature_importance = pd.DataFrame({\n",
    "        \"Feature\": features,\n",
    "        \"Importance\": model.feature_importances_\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "    st.bar_chart(feature_importance.set_index(\"Feature\"))\n",
    "\n",
    "# Run the app with `streamlit run app.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d8a9f30",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.47.2-cp311-cp311-win_amd64.whl.metadata (25 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement install (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for install\n"
     ]
    }
   ],
   "source": [
    "!pip install shap install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7268527",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
